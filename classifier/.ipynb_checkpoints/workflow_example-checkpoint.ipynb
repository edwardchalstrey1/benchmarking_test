{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking for data science algorithms workflow: Example #1\n",
    "====\n",
    "\n",
    "**Algorithm:** Support Vector Classification of digit images (with sci-kit learn). Python code [here](https://github.com/edwardchalstrey1/benchmarking_test/blob/master/classifier/classifier.py).\n",
    "\n",
    "**Task:** Compare speed and performance of the algorithm in different evironments and for different versions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before getting started\n",
    "\n",
    "1) [Install Docker](https://docs.docker.com/v17.09/engine/installation/) on all machines required for benchmarking and set up your account on [Docker Hub](https://hub.docker.com). In this example, we are just using the local machine. \n",
    "\n",
    "2) Make sure the software (data science algorithm) you are developing is version controlled so you can push newer versions to GitHub\n",
    "\n",
    "3) Your algorithm/code should output benchmark data that can can be collected when it is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run our algorithm locally and collect benchmark results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_report, local_results = classifier.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        88\n",
      "           1       1.00      0.74      0.85        91\n",
      "           2       1.00      0.64      0.78        86\n",
      "           3       1.00      0.64      0.78        91\n",
      "           4       1.00      0.55      0.71        92\n",
      "           5       0.93      0.98      0.95        91\n",
      "           6       1.00      0.68      0.81        91\n",
      "           7       1.00      0.49      0.66        89\n",
      "           8       0.25      1.00      0.40        88\n",
      "           9       1.00      0.61      0.76        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       899\n",
      "   macro avg       0.92      0.70      0.75       899\n",
      "weighted avg       0.92      0.70      0.75       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(local_report) # Sci-kit learns performance stats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Docker image for our algorithm and push to Docker Hub\n",
    "---\n",
    "\n",
    "1) Create a docker image for installing your software on a linux distribution with the bare essential dependencies and outputting the benchmark stats. Example Dockerfile [here](https://github.com/edwardchalstrey1/benchmarking_test/blob/master/classifier/Dockerfile).\n",
    "\n",
    "2) Build a docker container and tag the version as latest. Optionally also tag a version: ```docker build -t edwardchalstrey/classifier:latest -t edwardchalstrey/classifier:1.0 .```\n",
    "\n",
    "3) Push to Docker Hub. This allows you to then pull the container to any machine you wish to benchmark on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  56.32kB\r",
      "\r\n",
      "Step 1/8 : FROM python:3\n",
      " ---> ac069ebfe1e1\n",
      "Step 2/8 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 5a84d23aa7b5\n",
      "Step 3/8 : RUN pip3 install numpy\n",
      " ---> Using cache\n",
      " ---> 4383ac463a3b\n",
      "Step 4/8 : RUN pip3 install scipy\n",
      " ---> Using cache\n",
      " ---> 6fa2c9da864b\n",
      "Step 5/8 : RUN pip3 install scikit-learn\n",
      " ---> Using cache\n",
      " ---> 0b888dbaed11\n",
      "Step 6/8 : COPY classifier.py /classifier.py\n",
      " ---> Using cache\n",
      " ---> 584d3a9d4955\n",
      "Step 7/8 : COPY display_classifier_results.py /display_classifier_results.py\n",
      " ---> Using cache\n",
      " ---> aaa2e8a68fa3\n",
      "Step 8/8 : CMD python3 display_classifier_results.py\n",
      " ---> Using cache\n",
      " ---> 9cfc28a647ce\n",
      "Successfully built 9cfc28a647ce\n",
      "Successfully tagged edwardchalstrey/classifier:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build -t edwardchalstrey/classifier:latest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/edwardchalstrey/classifier]\n",
      "c9a5858f6be4: Preparing\n",
      "da35d2adcbff: Preparing\n",
      "f12d5b3c5c82: Preparing\n",
      "337d3babfd9c: Preparing\n",
      "493622b04a5f: Preparing\n",
      "65ef2276d16f: Preparing\n",
      "4b381ae03f9a: Preparing\n",
      "08a5b66845ac: Preparing\n",
      "65ef2276d16f: Waiting\n",
      "4b381ae03f9a: Waiting\n",
      "08a5b66845ac: Waiting\n",
      "88a85bcf8170: Preparing\n",
      "65860ac81ef4: Preparing\n",
      "a22a5ac18042: Preparing\n",
      "65860ac81ef4: Waiting\n",
      "88a85bcf8170: Waiting\n",
      "6257fa9f9597: Preparing\n",
      "578414b395b9: Preparing\n",
      "abc3250a6c7f: Preparing\n",
      "13d5529fd232: Preparing\n",
      "578414b395b9: Waiting\n",
      "abc3250a6c7f: Waiting\n",
      "13d5529fd232: Waiting\n",
      "6257fa9f9597: Waiting\n",
      "a22a5ac18042: Waiting\n",
      "da35d2adcbff: Layer already exists\n",
      "c9a5858f6be4: Layer already exists\n",
      "493622b04a5f: Layer already exists\n",
      "f12d5b3c5c82: Layer already exists\n",
      "337d3babfd9c: Layer already exists\n",
      "4b381ae03f9a: Layer already exists\n",
      "65860ac81ef4: Layer already exists\n",
      "65ef2276d16f: Layer already exists\n",
      "08a5b66845ac: Layer already exists\n",
      "88a85bcf8170: Layer already exists\n",
      "6257fa9f9597: Layer already exists\n",
      "578414b395b9: Layer already exists\n",
      "abc3250a6c7f: Layer already exists\n",
      "a22a5ac18042: Layer already exists\n",
      "13d5529fd232: Layer already exists\n",
      "latest: digest: sha256:e8cdb53e7a420b9b408a65ad06939932d6429e118fa4de3f549cac1f069be33c size: 3480\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker push edwardchalstrey/classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from edwardchalstrey/classifier\n",
      "Digest: sha256:e8cdb53e7a420b9b408a65ad06939932d6429e118fa4de3f549cac1f069be33c\n",
      "Status: Image is up to date for edwardchalstrey/classifier:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker pull edwardchalstrey/classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the docker container and collect benchmark stats\n",
    "-----\n",
    "\n",
    "Here I save the results to stdout, but you could instead save the benchmark stats to a file within the container then use ```docker cp``` to move this outside the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out docker_results\n",
    "docker run edwardchalstrey/classifier:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_results = ast.literal_eval(docker_results)\n",
    "docker_report, docker_results = docker_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do they compare?\n",
    "---\n",
    "\n",
    "In this example, the benchmark stats I have collected are the preformance stats measured by sci-kit learn, as well as the time taken to fit the classification model and the time it takes to predict the catagories of the test data.\n",
    "\n",
    "Here I have labelled the results from running the algorithm code on my machine directly as \"Basic\" and the Docker version as \"Container\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Version      </td><td>Training time (s)  </td><td>Prediction time (s) </td><td>Performance (micro avg f1 score)</td></tr>\n",
       "<tr><td>Basic 1.0    </td><td>0.10861325263977051</td><td>0.052420854568481445</td><td>0.6974416017797553              </td></tr>\n",
       "<tr><td>Container 1.0</td><td>0.1337735652923584 </td><td>0.07343864440917969 </td><td>0.6974416017797553              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = [\"Version\"]\n",
    "c_results = [\"Basic 1.0\"]\n",
    "d_results = [\"Container 1.0\"]\n",
    "for k, v in local_results.items():\n",
    "    headers.append(k)\n",
    "    c_results.append(v)\n",
    "for k, v in docker_results.items():\n",
    "    d_results.append(v)\n",
    "display(HTML(tabulate.tabulate([headers, c_results, d_results], tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        88\n",
      "           1       1.00      0.74      0.85        91\n",
      "           2       1.00      0.64      0.78        86\n",
      "           3       1.00      0.64      0.78        91\n",
      "           4       1.00      0.55      0.71        92\n",
      "           5       0.93      0.98      0.95        91\n",
      "           6       1.00      0.68      0.81        91\n",
      "           7       1.00      0.49      0.66        89\n",
      "           8       0.25      1.00      0.40        88\n",
      "           9       1.00      0.61      0.76        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       899\n",
      "   macro avg       0.92      0.70      0.75       899\n",
      "weighted avg       0.92      0.70      0.75       899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        88\n",
      "           1       1.00      0.74      0.85        91\n",
      "           2       1.00      0.64      0.78        86\n",
      "           3       1.00      0.64      0.78        91\n",
      "           4       1.00      0.55      0.71        92\n",
      "           5       0.93      0.98      0.95        91\n",
      "           6       1.00      0.68      0.81        91\n",
      "           7       1.00      0.49      0.66        89\n",
      "           8       0.25      1.00      0.40        88\n",
      "           9       1.00      0.61      0.76        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       899\n",
      "   macro avg       0.92      0.70      0.75       899\n",
      "weighted avg       0.92      0.70      0.75       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(local_report) # Performance stats are identical\n",
    "print(docker_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's release the next version of our algorithm\n",
    "----\n",
    "1) Navigate to Dockerhub and click the [builds tab](https://cloud.docker.com/repository/docker/edwardchalstrey/classifier/builds) for your algorithm's repository and set up [build rules](https://docs.docker.com/docker-hub/builds/) to your liking. Configure it to use the github repo where your algorithm code is mantained. In this case I have set it to simply build a new version of the container and tag as ```edwardchalstrey/classifier:latest``` whenever there is a push to the master branch of [my GitHub repo](https://github.com/edwardchalstrey1/benchmarking_test).\n",
    "\n",
    "2) Edit the classifier algorithm to create a new version (e.g. version 1.1)\n",
    "\n",
    "3) Commit and push changes to github\n",
    "\n",
    "4) The latest version can then be pulled: ```docker pull edwardchalstrey/classifier:latest```\n",
    "\n",
    "**Instead of using the automated build here I do a regular build:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  56.32kB\r",
      "\r\n",
      "Step 1/8 : FROM python:3\n",
      " ---> ac069ebfe1e1\n",
      "Step 2/8 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 5a84d23aa7b5\n",
      "Step 3/8 : RUN pip3 install numpy\n",
      " ---> Using cache\n",
      " ---> 4383ac463a3b\n",
      "Step 4/8 : RUN pip3 install scipy\n",
      " ---> Using cache\n",
      " ---> 6fa2c9da864b\n",
      "Step 5/8 : RUN pip3 install scikit-learn\n",
      " ---> Using cache\n",
      " ---> 0b888dbaed11\n",
      "Step 6/8 : COPY classifier.py /classifier.py\n",
      " ---> 21a5d2032eb4\n",
      "Step 7/8 : COPY display_classifier_results.py /display_classifier_results.py\n",
      " ---> f8cbb7851539\n",
      "Step 8/8 : CMD python3 display_classifier_results.py\n",
      " ---> Running in 4f3510693745\n",
      "Removing intermediate container 4f3510693745\n",
      " ---> cbf3fe391e8e\n",
      "Successfully built cbf3fe391e8e\n",
      "Successfully tagged edwardchalstrey/classifier:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build -t edwardchalstrey/classifier:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then collect benchmark stats again for the new version of your algorithm and compare to previous versions and other machines/environments\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out docker_results_1\n",
    "docker run edwardchalstrey/classifier:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_report_1, docker_results_1 = docker_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Version      </td><td>Training time (s)   </td><td>Prediction time (s) </td><td>Performance (micro avg f1 score)</td></tr>\n",
       "<tr><td>Basic 1.0    </td><td>0.10861325263977051 </td><td>0.052420854568481445</td><td>0.6974416017797553              </td></tr>\n",
       "<tr><td>Container 1.0</td><td>0.1337735652923584  </td><td>0.07343864440917969 </td><td>0.6974416017797553              </td></tr>\n",
       "<tr><td>Container 1.1</td><td>0.044446706771850586</td><td>0.04564070701599121 </td><td>0.9688542825361512              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d1_results = [\"Container 1.1\"]\n",
    "for k, v in docker_results_1.items():\n",
    "    d1_results.append(v)\n",
    "display(HTML(tabulate.tabulate([headers, c_results, d_results, d1_results], tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        88\n",
      "           1       0.99      0.97      0.98        91\n",
      "           2       0.99      0.99      0.99        86\n",
      "           3       0.98      0.87      0.92        91\n",
      "           4       0.99      0.96      0.97        92\n",
      "           5       0.95      0.97      0.96        91\n",
      "           6       0.99      0.99      0.99        91\n",
      "           7       0.96      0.99      0.97        89\n",
      "           8       0.94      1.00      0.97        88\n",
      "           9       0.93      0.98      0.95        92\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docker_report_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
